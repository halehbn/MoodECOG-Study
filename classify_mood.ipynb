{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before attempting to load data, make sure to standardize your excel sheet to make your life easier.\n",
    "The excel sheet should have:\n",
    "-Consistent category/column labels across subjects\n",
    "-First row is category/column labels\n",
    "-Keep extra information elsewhere\n",
    "-Be 'snug' left and top (we want it to be a simple table starting with corner cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy.io\n",
    "import seaborn as sns\n",
    "from scipy.signal import butter, hilbert, filtfilt\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mood_data(file_name):\n",
    "    \"\"\"\n",
    "    Evaluates an excel spreadsheet for IMS metrics and timestamps. Returns\n",
    "    a list of the depression and anxiety scores and a list of times.\n",
    "\n",
    "    Inputs:\n",
    "    file_name - a standardized excel sheet with category labels in the first row.\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(file_name)\n",
    "    df = df[['time', 'depression score', 'anxiety score']].dropna()\n",
    "    dep_score = [int(i) for i in df['depression score']]\n",
    "    anx_score = [int(i) for i in df['anxiety score']]\n",
    "    return list(dep_score), list(anx_score), list(df['time'])\n",
    "\n",
    "def get_neural(neural_data):\n",
    "    \"\"\"\n",
    "    Loads in the neural dataset and returns an array of the samples, an array of time,\n",
    "    and sampling frequency.\n",
    "\n",
    "    Inputs:\n",
    "    neural_data: h5 file containing neural data\n",
    "    \"\"\"\n",
    "    # Load neural data\n",
    "    fin = h5py.File(neural_data, 'r')\n",
    "\n",
    "    # Express channels\n",
    "    chan_label = fin.get('chanLabels')[()]\n",
    "\n",
    "    if isinstance(chan_label, bytes):\n",
    "        chan_clean = chan_label.decode('utf-8').replace(\"'\",'').replace(',','').replace('[','').replace(']','')\n",
    "        chan_label = chan_clean.split()\n",
    "\n",
    "    # Evaluate time\n",
    "    t_start = fin.get('start_timestamp')[()]\n",
    "    t_start_utc = datetime.datetime.utcfromtimestamp(int(t_start))\n",
    "\n",
    "    # Extract neural data\n",
    "    data_ecog = fin.get('dataset')\n",
    "    fs = int(fin.get('f_sample')[()])\n",
    "    t = np.linspace(0, len(data_ecog[0]) / fs, len(data_ecog[0]))\n",
    "    total_time = len(data_ecog[0]) / fs\n",
    "    t_end_utc = t_start_utc + datetime.timedelta(seconds = total_time)\n",
    "    return data_ecog, chan_label, t, t_start_utc, t_end_utc, fs\n",
    "\n",
    "\n",
    "def get_windows(neural_data, ims_file_name, window_length):\n",
    "    \"\"\"\n",
    "    Splices an h5 dataset into windows of neural activity corresponding to\n",
    "    VAS measures. Returns None if no IMS records within neural recording.\n",
    "\n",
    "    Inputs:\n",
    "    neural_data - h5 file containing neural data and labels\n",
    "    ims_file_name - standardized excel sheet containing ims information\n",
    "    window_length - length of extraction windows in minutes\n",
    "    \"\"\"\n",
    "    # Load vas data\n",
    "    dep_score, anx_score, ims_timestamps = get_mood_data(ims_file_name)\n",
    "\n",
    "    # Load neural data\n",
    "    data_mood, chs, t, t_start, t_end, fs = get_neural(neural_data)\n",
    "\n",
    "    # Establish time buffers for adequate samples\n",
    "    t_end_buffer = t_end - datetime.timedelta(seconds=60*window_length/2) # ensure enough samples\n",
    "    t_start_buffer = t_start + datetime.timedelta(seconds=60*window_length/2)\n",
    "    print('t_start_buffer', t_start_buffer)\n",
    "    print('t_end_buffer', t_end_buffer)\n",
    "\n",
    "    # Calculate timestamps and target sample\n",
    "    ims_times = [x.to_pydatetime().timestamp() - t_start.timestamp() for x in ims_timestamps if t_start_buffer < x < t_end_buffer]\n",
    "    if len(ims_times) == 0:\n",
    "        return None, None, None, None, None, None\n",
    "    dep_score_tracker = [dep_score[i] for i in range(len(dep_score)) if t_start_buffer < ims_timestamps[i] < t_end_buffer]\n",
    "    anx_score_tracker = [anx_score[i] for i in range(len(anx_score)) if t_start_buffer < ims_timestamps[i] < t_end_buffer]\n",
    "    target_sample = [int(i) * fs for i in ims_times]\n",
    "    print('target_sample', target_sample)\n",
    "    print('len channels', len(chs))\n",
    "\n",
    "    # Create windows\n",
    "    window_length_s = window_length*60*fs\n",
    "    start_frame = [int(i - window_length_s/2) for i in target_sample]\n",
    "    stop_frame = [int(i + window_length_s/2) for i in target_sample]\n",
    "\n",
    "    # Extract windows\n",
    "    neural_windows = np.zeros((len(target_sample), len(chs), stop_frame[0] - start_frame[0]))\n",
    "    file_tracker = []\n",
    "    print('neural_windows shape', neural_windows.shape)\n",
    "    print('data_mood shape', data_mood.shape)\n",
    "    \n",
    "    for i in range(len(target_sample)):\n",
    "        neural_windows[i, :, :] = data_mood[:, start_frame[i]:stop_frame[i]]\n",
    "        file_tracker.append(neural_data)\n",
    "    \n",
    "    return neural_windows, dep_score_tracker, anx_score_tracker, fs, chs, file_tracker, target_sample\n",
    "\n",
    "\n",
    "def extract_windows(directory, ims_file_name, window_length, output_name):\n",
    "    \"\"\"\n",
    "    Joins multiple windows of neural data together, maintaining\n",
    "    associated labels.\n",
    "    \n",
    "    Inputs:\n",
    "    directory - a path to the directory containing eeg data\n",
    "    ims_file_name - an excel spreadsheet of IMS records\n",
    "    window_length - length of extraction windows in minutes\n",
    "    output_name - resultant h5 file\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize combined arrays / list\n",
    "    combined_windows = None\n",
    "    combined_target_sample = None\n",
    "    combined_dep_score = None\n",
    "    combined_anx_score = None\n",
    "    combined_file_tracker = []\n",
    "\n",
    "    # Sort neural data chronologically\n",
    "    sorted_dir = sorted(os.listdir(directory))\n",
    "    if '.DS_Store' in sorted_dir:\n",
    "        sorted_dir.remove('.DS_Store')\n",
    "    \n",
    "    for file in sorted_dir:\n",
    "        neural_windows, dep_score_tracker, anx_score_tracker, fs, chs, file_tracker, target_sample = get_windows(directory + file, \n",
    "                                                                               ims_file_name,\n",
    "                                                                               window_length)\n",
    "        # Skip over files without IMS records\n",
    "        if dep_score_tracker is None:\n",
    "            continue\n",
    "\n",
    "        # Evaluate, starting with first dataset containing VAS records\n",
    "        print('Extracting ' + str(len(dep_score_tracker)) + ' IMS from ' + file)\n",
    "        if len(combined_file_tracker) == 0:\n",
    "            combined_windows = neural_windows\n",
    "            combined_target_sample = target_sample\n",
    "            combined_dep_score = dep_score_tracker\n",
    "            combined_anx_score = anx_score_tracker\n",
    "            combined_file_tracker = file_tracker\n",
    "            fsample = fs\n",
    "            channels = chs\n",
    "        else:\n",
    "            combined_windows = np.concatenate([combined_windows, neural_windows])\n",
    "            combined_file_tracker = combined_file_tracker + file_tracker\n",
    "            combined_target_sample = np.concatenate([combined_target_sample, target_sample])\n",
    "            combined_dep_score = np.concatenate([combined_dep_score, dep_score_tracker])\n",
    "            combined_anx_score = np.concatenate([combined_anx_score, anx_score_tracker])\n",
    "\n",
    "    # Create h5 file\n",
    "    ims_out = h5py.File(output_name, \"w\")\n",
    "    ims_out.create_dataset(\"neural_windows\", data=combined_windows, chunks=True)\n",
    "    ims_out.create_dataset(\"depression scores\", data=combined_dep_score)\n",
    "    ims_out.create_dataset(\"anxiety scores\", data=combined_anx_score)\n",
    "    ims_out.create_dataset(\"fs\", data=fsample, dtype='i8')\n",
    "    ims_out.create_dataset(\"file\", data=combined_file_tracker)\n",
    "    dt = h5py.special_dtype(vlen=str)\n",
    "    ims_out.create_dataset(\"channels\", data=channels, dtype=dt)\n",
    "    ims_out.create_dataset(\"target_sample\", data=combined_target_sample, dtype = 'i')\n",
    "    print('Extraction Complete')\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main\n",
    "\n",
    "directory = '/Users/haleh/Documents/School/UW/Research/Jeffery Herron/Mood Variation Decoding/Neural Data/eb06df40 Neural/' #specific subject and day name\n",
    "output = 'IMS_eb06df40_6_20min.h5'\n",
    "\n",
    "extract_windows(directory=directory, ims_file_name='survey_responses_ims.xlsx', window_length=20, output_name=output)\n",
    "\n",
    "##NOTE: for some reason, there are 1268 channels, this sounds wrong, need to debug furhter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering and calculating power in band\n",
    "def get_PIB(data,fs,f_low,f_high,order,axis):\n",
    "    '''\n",
    "    This function computes the average power in frequency band for any signal\n",
    "    Input\n",
    "        data = any signal in the form of (time, voltage)\n",
    "        f_low = low cutoff point of the desired frequency range\n",
    "        f_high = high cutoff point of the desired frequency range\n",
    "        fs = sampling frequency\n",
    "        order = order of butterworth bandpass filter\n",
    "        axis = axis to compute across (0 = 1D  signals, 1 = 2D signals)\n",
    "\n",
    "    Outputs\n",
    "        average = average power across frequency band\n",
    "  '''\n",
    "    #Butterworth bandpass filter\n",
    "    b,a = butter(order,[f_low,f_high],fs=fs,btype='band') \n",
    "    #Filtering the input signal with the butterworth bandpass filter\n",
    "    filtered = filtfilt(b,a,data)\n",
    "    #Hilbert transform of the filtered signal\n",
    "    data_hilbert = hilbert(filtered)\n",
    "    #power of the transformed signal\n",
    "    power = (abs(data_hilbert))**2\n",
    "    #Sum of the power across the time axis of the signal\n",
    "    total = np.sum(power, axis=axis)\n",
    "    return total\n",
    "\n",
    "def predict_pain(data_epoch, fsample, dep_score, ch_select, f_bands, f_band, label_splitter, test_split=0.30):\n",
    "    PIB_feat = np.zeros((len(dep_score), np.shape(data_epoch)[2]))\n",
    "    for vas in range(len(dep_score)):\n",
    "        for ep in range(np.shape(data_epoch)[2]):\n",
    "            low = f_bands[f_band][0]\n",
    "            high = f_bands[f_band][1]\n",
    "            PIB_feat[vas, ep] = get_PIB(signal=data_epoch[vas, ch_select, ep, :],\n",
    "                                        fs=fsample, f_low=low, f_high=high,\n",
    "                                        order=3, axis=0)\n",
    "    labels = np.repeat(dep_score, np.shape(data_epoch)[2])\n",
    "    split_labels = labels <= label_splitter\n",
    "\n",
    "    # Standardize features\n",
    "    PIB_feat = np.ravel(PIB_feat)\n",
    "    PIB_mean = np.mean(PIB_feat)\n",
    "    PIB_std = np.std(PIB_feat)\n",
    "    if PIB_std == 0:\n",
    "      return 0\n",
    "    PIB_feat_st = (PIB_feat - PIB_mean) / (PIB_std)\n",
    "    PIBs = np.reshape(np.array(PIB_feat_st), (len(PIB_feat_st), 1))\n",
    "\n",
    "    # Apply logistic regression\n",
    "    logr = LogisticRegression(max_iter=10000)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(PIBs, split_labels, test_size=test_split)\n",
    "    logr.fit(X_train, y_train)\n",
    "     \n",
    "    return logr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Load in the dataset\n",
    "    fin = h5py.File('IMS_eb06df40_6_20min.h5', 'r') # Extracted windows\n",
    "    pain_data = fin.get('neural_windows')[()]\n",
    "    chans = fin.get('channels')[()]\n",
    "    dep_scores = fin.get('depression scores')\n",
    "    anx_scores = fin.get('anxiety scores')\n",
    "    fs = fin.get('fs')[()]\n",
    "    print(dep_scores)\n",
    "\n",
    "    # Calculate features\n",
    "    f_bands = [[0.1,4],[4,8],[8,12],[12,30],[30,55],[65,115]] # Establish neural frequency band indices \n",
    "    f_bands_label = [\"delta\", \"theta\", \"alpha\", \"beta\", \"gamma\", \"high gamma\"]\n",
    "\n",
    "    # Epoch signal\n",
    "    epochs = 5\n",
    "    data_epoched = pain_data.reshape((len(dep_scores), len(chans), epochs, -1))\n",
    "\n",
    "    # Get features and labels\n",
    "    pred = predict_pain(data_epoch=data_epoched, fsample=fs, dep_score=dep_scores,\n",
    "                       f_bands=f_bands, ch_select=40, f_band=4, label_splitter=5)\n",
    "    # # # Evaluate combinations\n",
    "    acc_matrix = np.zeros((len(chans), len(f_bands)))\n",
    "\n",
    "    for i in range(1, len(chans)):\n",
    "        for j in range(len(f_bands)):\n",
    "            acc_matrix[i, j] = predict_pain(data_epoch=data_epoched, fsample=fs, intensity=dep_scores,\n",
    "                       f_bands=f_bands, ch_select=i, f_band=j, label_splitter=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "664e399882684c14d88a282cae4411fa5be4f6a8bf1db193885ee03269804ea9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
